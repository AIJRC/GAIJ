{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_token_id: 128009\n",
      "eos_token_id: 128009\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your LLaMA 3 model directory\n",
    "model_path = \"/Users/nunocalaim/.llama/llama-hf\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Ensure the pad token is set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Set the pad_token_id and eos_token_id in model configuration\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Print token IDs to confirm they are integers\n",
    "print(\"pad_token_id:\", model.config.pad_token_id)\n",
    "print(\"eos_token_id:\", model.config.eos_token_id)\n",
    "\n",
    "# Make sure eos_token_id and pad_token_id are valid integers\n",
    "assert isinstance(model.config.pad_token_id, int), \"pad_token_id should be an integer.\"\n",
    "assert isinstance(model.config.eos_token_id, int), \"eos_token_id should be an integer.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt):\n",
    "    # Tokenize the input text and create an attention mask\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    # Generate a response using the model\n",
    "    output = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=150,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=model.config.pad_token_id  # Use pad_token_id from the model's config\n",
    "    )\n",
    "\n",
    "    # Decode and print the output text\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Remove the input prompt from the generated response\n",
    "    generated_text = generated_text[len(prompt):].strip()\n",
    "    print(\"Response:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder containing the markdown files\n",
    "folder_path = \"../converted\"\n",
    "\n",
    "# Use glob to list all .md files in the folder\n",
    "markdown_files = glob.glob(os.path.join(folder_path, \"*.md\"))\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "\n",
    "file_path = markdown_files[np.random.randint(0, len(markdown_files))]\n",
    "file_content = read_file(file_path)\n",
    "# print(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Here is the extracted information in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"companyName\": \"CENTER TAKST & PROSJEKT AS\",\n",
      "  \"companyAddress\": \"Skiveien 18, 1816 SKIPTVET\",\n",
      "  \"shareholders\": [\n",
      "    {\n",
      "      \"name\": \"Bent Wessel Eide\",\n",
      "      \"type\": \"Director\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Einar S. Andersen\",\n",
      "      \"type\": \"Shareholder\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Morten A. Larsen\",\n",
      "      \"type\": \"Shareholder\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"SÃ¸ren A. Jensen\",\n",
      "      \"type\": \"Shareholder\"\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"<|system|> You are a helpful assistant. You process tax-records of norwegian companies and extract information from them. This is the tax-record you will base your answers on {file_content}\\n\\n you provide your response in JSON format\\n<|user|> I want to extract the following information from the tax-record: -company name; -company address; list with names of shareholders; -number of employees; does the company own or rent properties?\\n<|assistant|>\"\n",
    "\n",
    "generate_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
