{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_paths = '../converted'\n",
    "json_paths = '../extracted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use glob to list all .md files in the folder\n",
    "markdown_files = glob.glob(os.path.join(md_paths, \"*.md\"))\n",
    "np.random.shuffle(markdown_files)\n",
    "os.makedirs(json_paths, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your LLaMA 3 model directory\n",
    "model_path = \"/Users/nunocalaim/.llama/llama-hf\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Ensure the pad token is set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Set the pad_token_id and eos_token_id in model configuration\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Print token IDs to confirm they are integers\n",
    "print(\"pad_token_id:\", model.config.pad_token_id)\n",
    "print(\"eos_token_id:\", model.config.eos_token_id)\n",
    "\n",
    "# Make sure eos_token_id and pad_token_id are valid integers\n",
    "assert isinstance(model.config.pad_token_id, int), \"pad_token_id should be an integer.\"\n",
    "assert isinstance(model.config.eos_token_id, int), \"eos_token_id should be an integer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, json_path):\n",
    "    # Tokenize the input text and create an attention mask\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    # Generate a response using the model\n",
    "    output = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=300,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=model.config.pad_token_id  # Use pad_token_id from the model's config\n",
    "    )\n",
    "\n",
    "    # Decode and print the output text\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Remove the input prompt from the generated response\n",
    "    generated_text = generated_text[len(prompt)-100:].strip()\n",
    "\n",
    "    # print(\"Response:\", generated_text)\n",
    "\n",
    "    # Use regex to extract the JSON block from the response\n",
    "    json_str_match = re.search(r'{.*}', generated_text, re.DOTALL)\n",
    "\n",
    "    if json_str_match:\n",
    "        json_str = json_str_match.group(0)\n",
    "        # Parse the JSON string\n",
    "        try:\n",
    "            json_data = json.loads(json_str)\n",
    "\n",
    "            # Save the JSON data to a file\n",
    "            with open(json_path, 'w') as json_file:\n",
    "                json.dump(json_data, json_file, indent=4)  # Save the JSON with indentation for readability\n",
    "\n",
    "            print(f\"JSON data saved to '{json_path}'\")\n",
    "            print(\"Extracted JSON:\", json_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "            print(f\"generated text is {generated_text}\")\n",
    "    else:\n",
    "        print(\"No JSON found in the response\")\n",
    "        print(f\"generated text is {generated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(content, json_path):\n",
    "    prompt = f\"\"\"\n",
    "    <|system|> You are a helpful assistant. You process tax records of Norwegian companies and extract specific information from them. This is the tax record you will base your answers on: {content}\n",
    "\n",
    "    You provide your response only in a predefined JSON format and nothing else. Do not include any explanation, comments, or extra informationâ€”only the JSON.\n",
    "\n",
    "    The JSON structure should strictly follow this format:\n",
    "\n",
    "    \"json\"\n",
    "    {{\n",
    "        \"company_name\": \"string\",          \n",
    "        \"company_id\": \"string\",            \n",
    "        \"leadership\": {{\n",
    "            \"CEO\": \"string or null\",       \n",
    "            \"board_members\": [\n",
    "                \"string or null\"           \n",
    "            ],\n",
    "            \"chairman_of_the_board\": \"string or null\" \n",
    "        }},\n",
    "        \"subsidiaries\": [\n",
    "            \"string or null\"               \n",
    "        ],\n",
    "        \"parent_company\": \"string or null\", \n",
    "        \"profit_status\": \"boolean or null\", \n",
    "        \"property_status\": \"string\",        \n",
    "        \"number_of_employees\": \"integer or null\" \n",
    "    }}\n",
    "\n",
    "    <|user|> I want to extract the following information from the tax record:\n",
    "\n",
    "    - Company name\n",
    "    - Company ID\n",
    "    - Leadership: names of CEO, board members, and chairman of the board\n",
    "    - A list of subsidiaries if they exist\n",
    "    - The parent company if it exists\n",
    "    - Whether the company made a profit\n",
    "    - Whether the company owns or rents property\n",
    "    - The number of employees\n",
    "\n",
    "    Remember, only return the JSON. No explanations.\n",
    "    <|assistant|>\n",
    "    \"\"\"\n",
    "\n",
    "    generate_response(prompt, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_md(path):\n",
    "    match = re.search(r\"/(\\d+)_arso_2020\", path)\n",
    "    print(match)\n",
    "    if match:\n",
    "        id = match.group(1)  # group(1) will contain everything before \"_arso_2020\"\n",
    "    else:\n",
    "        return None\n",
    "    json_path = f\"{json_paths}/{id}.json\"\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"processing {path}...\")\n",
    "        with open(path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        run_model(content, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in markdown_files:\n",
    "    print(path)\n",
    "    process_md(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
